{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "7f9c64fb",
      "metadata": {
        "id": "7f9c64fb"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from datasets import load_dataset\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, ConfusionMatrixDisplay\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "102d7074",
      "metadata": {
        "id": "102d7074"
      },
      "source": [
        "# Deep Average Network для определения сентимента "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e15a9f7c",
      "metadata": {
        "id": "e15a9f7c"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(path, num_tokens=100_000):\n",
        "    \"\"\"\n",
        "    Load by file path no more emdeddings than tokens number.\n",
        "\n",
        "    path -- file path to embeddings\n",
        "    num_tokens -- tokens number (default 100_000)\n",
        "    \"\"\"\n",
        "    token2index: Dict[str, int] = {}\n",
        "    embeddings = []\n",
        "    with open(path) as file_object:\n",
        "        vocab_size, embedding_dim = file_object.readline().strip().split()\n",
        "        vocab_size, embedding_dim = int(vocab_size), int(embedding_dim)\n",
        "        num_tokens = vocab_size if num_tokens <= 0 else num_tokens\n",
        "        token2index['PAD'] = 0\n",
        "        embeddings.append(np.zeros(embedding_dim))\n",
        "        token2index['UNK'] = 1\n",
        "        embeddings.append(np.ones(embedding_dim))\n",
        "        for line in tqdm(file_object, total=num_tokens, desc='Reading embeddings file'):\n",
        "            parts = line.strip().split()\n",
        "            token = ' '.join(parts[:-embedding_dim]).lower()\n",
        "            if token in token2index:\n",
        "                continue\n",
        "            embedding = np.array(list(map(float, parts[-embedding_dim:])))\n",
        "            token2index[token] = len(token2index)\n",
        "            embeddings.append(embedding)\n",
        "            if len(token2index) == num_tokens:\n",
        "                break\n",
        "    embeddings_matrix: np.array = np.array(embeddings)\n",
        "    assert(len(token2index) == embeddings_matrix.shape[0])\n",
        "    \n",
        "    return token2index, embeddings_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnZJc_o7lce1",
        "outputId": "b97b0014-2d51-48a4-9435-2c6f35572bec"
      },
      "id": "cnZJc_o7lce1",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 06:11:34--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  25.4MB/s    in 50s     \n",
            "\n",
            "2022-02-10 06:12:25 (25.0 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n",
            "gzip: cc.ru.300.vec already exists; do you wish to overwrite (y or n)? н\n",
            "\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46b2b68",
      "metadata": {
        "id": "c46b2b68"
      },
      "source": [
        "## Загружаем данные из библиотеки\n",
        "Мы сразу получим `torch.utils.data.Dataset`, который сможем передать в `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e54fdaa8",
      "metadata": {
        "id": "e54fdaa8",
        "outputId": "d2999e9b-e40c-4a1f-b522-9283d71edf90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
            "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
            "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"tweet_eval\"\n",
        "dataset_name = \"sentiment\"\n",
        "\n",
        "train_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"train\")\n",
        "valid_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"validation\")\n",
        "test_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad4a0650",
      "metadata": {
        "id": "ad4a0650"
      },
      "source": [
        "## `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dc742027",
      "metadata": {
        "id": "dc742027"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "49bf6b50",
      "metadata": {
        "id": "49bf6b50",
        "outputId": "2b2ac9a8-a58a-4638-9f93-3b76889467e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': tensor([2, 0]),\n",
              " 'text': ['John Cena has been named as the 2nd most Charitable Athlete in the world..  1st. C Ronaldo-  2nd .John Cena  and...',\n",
              "  'Happy Friday: A health worker who may have had contact with Ebola is on a frigging cruise ship']}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "    break\n",
        "\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3b7ce86b",
      "metadata": {
        "id": "3b7ce86b"
      },
      "outputs": [],
      "source": [
        "def empty_collate(batch):\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "26f0fe92",
      "metadata": {
        "id": "26f0fe92"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=empty_collate)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=empty_collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=empty_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "942cf78e",
      "metadata": {
        "id": "942cf78e",
        "outputId": "536a7513-2c79-4428-c922-e95a526e37a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 1,\n",
              "  'text': 'De Biasi (coach ALB): \"Ronaldo better keeps quiet tomorrow or Messi will get my vote for the Ballon d\\'Or this time.\"'},\n",
              " {'label': 1,\n",
              "  'text': 'Kane returns Monday on #Raw will we see the mask or not #WWE'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "    break\n",
        "\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3b9ddcca",
      "metadata": {
        "id": "3b9ddcca"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    \n",
        "    def __init__(self, base_tokenizer, token2index, pad_token, unk_token, max_length):\n",
        "        \n",
        "        self._base_tokenizer = base_tokenizer  # например ToktokTokenizer()\n",
        "        \n",
        "        self.token2index = token2index  # словарь из load_embeddings()\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.token2index[self.pad_token]\n",
        "        \n",
        "        self.unk_token = unk_token\n",
        "        self.unk_index = self.token2index[self.unk_token]\n",
        "        \n",
        "        self.max_length = max_length\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"\n",
        "        В этом методе нужно разделить строку текста на токены\n",
        "        \"\"\"\n",
        "        return self._base_tokenizer.tokenize(text)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "        \"\"\"\n",
        "        В этом методе нужно перевести список токенов в список с индексами этих токенов\n",
        "        \"\"\"\n",
        "        tokens_indices = [self.token2index.get(token, self.unk_index) \n",
        "                          for token in tokenized_text]\n",
        "        return tokens_indices\n",
        "        \n",
        "    def padding(self, tokens_indices):\n",
        "        \"\"\"\n",
        "        В этом методе нужно сделать длину tokens_indices равной self.max_length\n",
        "        Опционально убрать повторяющиеся unk'и\n",
        "        \"\"\"\n",
        "        padded_indices = [self.pad_index] * self.max_length\n",
        "        for i, token_i in enumerate(tokens_indices[:self.max_length]):\n",
        "            padded_indices[i] = token_i\n",
        "            \n",
        "        return padded_indices\n",
        "    \n",
        "    def __call__(self, text):\n",
        "        \"\"\"\n",
        "        В этом методе нужно перевести строку с текстом в вектор с индексами слов нужно размера (self.max_length)\n",
        "        \"\"\"\n",
        "        return self.padding(self.indexing(self.tokenize(text)))\n",
        "        \n",
        "    def collate(self, batch):\n",
        "        \n",
        "        tokenized_texts = list()\n",
        "        labels = list()\n",
        "        \n",
        "        for sample in batch:\n",
        "            tokenized_texts.append(self(sample['text']))\n",
        "            labels.append(sample['label'])\n",
        "            \n",
        "        tokenized_texts = torch.LongTensor(tokenized_texts)  # перевод в torch.Tensor\n",
        "        labels = torch.LongTensor(labels)  # перевод в torch.Tensor\n",
        "        \n",
        "        return tokenized_texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "XuIxbX7nyZAo"
      },
      "id": "XuIxbX7nyZAo",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2index, embeddings_matrix = load_embeddings(\"/content/cc.ru.300.vec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj6gV2tDyLTs",
        "outputId": "7c4c20a7-c1a5-431c-dc6f-6aa455cad076"
      },
      "id": "gj6gV2tDyLTs",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading embeddings file: 117085it [00:11, 10615.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(\n",
        "    base_tokenizer=ToktokTokenizer(),\n",
        "    token2index=token2index,\n",
        "    pad_token=\"PAD\",\n",
        "    unk_token=\"UNK\",\n",
        "    max_length=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "jr7EQ5DDxtYG"
      },
      "id": "jr7EQ5DDxtYG",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "40268f8c",
      "metadata": {
        "id": "40268f8c"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=tokenizer.collate)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=tokenizer.collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=tokenizer.collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "d293b759",
      "metadata": {
        "id": "d293b759"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "87752ad7",
      "metadata": {
        "id": "87752ad7"
      },
      "outputs": [],
      "source": [
        "assert(isinstance(x, torch.Tensor))\n",
        "assert(len(x.size()) == 2)\n",
        "\n",
        "assert(isinstance(y, torch.Tensor))\n",
        "assert(len(y.size()) == 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff1f451c",
      "metadata": {
        "id": "ff1f451c"
      },
      "source": [
        "# Я выбрала метрику Accuracy\n",
        "Почему я выбрала эту метрику:  \n",
        "в обзорной статье о различных подходов к sentiment-анализу в твиттере Giachanou, A., & Crestani, F. (2016). Like it or not: A survey of twitter sentiment analysis methods (https://dl.acm.org/doi/abs/10.1145/2938640) авторы называют метрику Accuracy самым популярным выбором, поскольку фактически это проблема классификации, и Accuracy -- классическая метрика для нее. Эта метрика оценивает, как часто модель делает верное предсказание."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "da42260c",
      "metadata": {
        "id": "da42260c"
      },
      "outputs": [],
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.EmbeddingBag.from_pretrained(\n",
        "            embeddings=torch.from_numpy(embedding_matrix).to(torch.float32),\n",
        "            mode='mean',\n",
        "            padding_idx=0,\n",
        "            max_norm=10.0,\n",
        "            freeze=False,\n",
        "        )\n",
        "        self.linear = nn.Linear(embedding_matrix.shape[1], batch_size*2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output = nn.Linear(batch_size*2, 3)\n",
        "        self.bnorm = nn.BatchNorm1d(batch_size*2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_embed = self.embedding_layer(x)\n",
        "        x_embed = self.linear(x_embed)\n",
        "        x_embed = self.relu(x_embed)\n",
        "        x_embed = self.bnorm(x_embed)\n",
        "        x_embed = self.output(x_embed)\n",
        "        \n",
        "        return x_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "7966f715",
      "metadata": {
        "id": "7966f715"
      },
      "outputs": [],
      "source": [
        "model = DeepAverageNetwork(embeddings_matrix)\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5efad1d1",
      "metadata": {
        "id": "5efad1d1"
      },
      "source": [
        "## Задайте функцию потерь и оптимизатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "34c552fa",
      "metadata": {
        "id": "34c552fa"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628847fe",
      "metadata": {
        "id": "628847fe"
      },
      "source": [
        "## Сделайте цикл обучения"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 7  # Задайте количество эпох\n",
        "train_loss = []\n",
        "train_accuracy = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "warmup_ratio = 0.3\n",
        "num_training_steps = len(train_loader) * NUM_EPOCHS\n",
        "num_warmup = int(round(num_training_steps * warmup_ratio))\n",
        "\n",
        "lr_sched = get_cosine_schedule_with_warmup(optimizer=optimizer, num_training_steps=num_training_steps, num_warmup_steps=num_warmup)\n",
        "\n",
        "for n_epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # train\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    epoch_loss = []\n",
        "    for i, (x, y) in enumerate(tqdm(train_loader, desc=f\"Train Epoch {n_epoch}\")):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        loss_value = loss(logits, y)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        lr_sched.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        epoch_loss.append(loss_value.item())\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1)\n",
        "            y_pred_batch = y_pred_batch.detach().cpu().numpy()\n",
        "            y_true_batch = y.detach().cpu().numpy()\n",
        "            \n",
        "            y_pred += list(y_pred_batch)\n",
        "            y_true += list(y_true_batch)\n",
        "                \n",
        "    train_loss.append(np.mean(epoch_loss))\n",
        "    ep_train_accuracy = accuracy_score(y_true, y_pred)\n",
        "    train_accuracy.append(ep_train_accuracy)\n",
        "\n",
        "    # validation\n",
        "    epoch_val_loss = []\n",
        "    with torch.no_grad():\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "        for x, y in valid_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            logits = model(x)\n",
        "            epoch_val_loss.append(loss(logits, y).item())\n",
        "            y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1).cpu().numpy()\n",
        "            y_true_batch = y.cpu().numpy()\n",
        "            \n",
        "            y_pred += list(y_pred_batch)\n",
        "            y_true += list(y_true_batch)\n",
        "            \n",
        "        ep_val_accuracy = accuracy_score(y_true, y_pred)\n",
        "        val_accuracy.append(ep_val_accuracy)\n",
        "        val_loss.append(np.mean(epoch_val_loss))\n",
        "    \n",
        "    print(f\"Train Accuracy: {ep_train_accuracy:.4f}, Val Accuracy: {ep_val_accuracy:.4f}\")\n",
        "    print(f\"Train Loss: {np.mean(epoch_loss):.4f}, Val Loss: {np.mean(epoch_val_loss):.4f}\")\n",
        "    \n",
        "# test\n",
        "y_pred = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1).cpu().numpy()\n",
        "        y_true_batch = y.cpu().numpy()\n",
        "\n",
        "        y_pred += list(y_pred_batch)\n",
        "        y_true += list(y_true_batch)\n",
        "        \n",
        "test_accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnwZ2iMV9x2I",
        "outputId": "2564c73a-c386-4dde-cfba-7a42ffcec385"
      },
      "id": "cnwZ2iMV9x2I",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 0: 100%|██████████| 357/357 [00:19<00:00, 18.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.4913, Val Accuracy: 0.5550\n",
            "Train Loss: 1.0076, Val Loss: 0.9281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 1: 100%|██████████| 357/357 [00:18<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.5830, Val Accuracy: 0.5565\n",
            "Train Loss: 0.8886, Val Loss: 0.9047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2: 100%|██████████| 357/357 [00:18<00:00, 19.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.5999, Val Accuracy: 0.5750\n",
            "Train Loss: 0.8581, Val Loss: 0.8861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3: 100%|██████████| 357/357 [00:17<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6162, Val Accuracy: 0.5890\n",
            "Train Loss: 0.8334, Val Loss: 0.8773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4: 100%|██████████| 357/357 [00:18<00:00, 19.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6265, Val Accuracy: 0.5905\n",
            "Train Loss: 0.8147, Val Loss: 0.8798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5: 100%|██████████| 357/357 [00:18<00:00, 19.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6356, Val Accuracy: 0.5965\n",
            "Train Loss: 0.7995, Val Loss: 0.8781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 6: 100%|██████████| 357/357 [00:18<00:00, 19.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6417, Val Accuracy: 0.5940\n",
            "Train Loss: 0.7883, Val Loss: 0.8824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [00:02<00:00, 41.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.4907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjFV_nEaUs4i",
        "outputId": "be099c49-592a-4ca8-d369-51e4e8fabbf6"
      },
      "id": "CjFV_nEaUs4i",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.13      0.21      3972\n",
            "           1       0.55      0.68      0.61      5937\n",
            "           2       0.36      0.63      0.46      2375\n",
            "\n",
            "    accuracy                           0.49     12284\n",
            "   macro avg       0.50      0.48      0.43     12284\n",
            "weighted avg       0.53      0.49      0.45     12284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "22S-DcNPVmrA",
        "outputId": "0f320a83-56f2-466b-f4d6-0d536fe200ee"
      },
      "id": "22S-DcNPVmrA",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9342c64890>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87583e79",
      "metadata": {
        "id": "87583e79"
      },
      "source": [
        "# Выводы\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты получились не очень впечатляющие, и я не уверена, в чем проблема. Хуже всего получилось с негативным лейблом, модели свойствено принимать его за нейтральный, а вот с нейтральным и позитивным нормально, при этом модель скорее путает их друг с другом, чем с негативными. Сложно сказать, почему так, может быть не хватило данных или они получились не очень качественными. Из личных успехов -- удалось написать что-то работающее без ошибок, хотелось бы делать это и дальше. "
      ],
      "metadata": {
        "id": "QVCv1K6IYt6D"
      },
      "id": "QVCv1K6IYt6D"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Копия блокнота \"DAN Task.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
